{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manditory Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def send_http_request(url: str, body=None, method=\"POST\"):\n",
    "    try:\n",
    "        response = requests.request(method, url, json=body)\n",
    "        # Check if the request was successful (status code 200)        \n",
    "        if response.status_code == 200:\n",
    "            content_type = response.headers.get('Content-Type')\n",
    "            if content_type and 'application/json' in content_type:\n",
    "                try:\n",
    "                    return response.json()\n",
    "                except requests.exceptions.JSONDecodeError as e1:\n",
    "                    return response.text\n",
    "            else:\n",
    "                return response.text\n",
    "\n",
    "        else:\n",
    "            print(f\"Request exited with status code {response.status_code}: {response.reason}\")\n",
    "    except requests.RequestException as e:\n",
    "        return e\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant mapping between exercise names and their root derivation trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_model_ids = {\n",
    "    'Courses': ['JDKw8yJZF5fiP3jv3', 'PSqwzYAfW9dFAa9im'],\n",
    "    'ProductionLine_v2_v3': ['aTwuoJgesSd8hXXEP', 'bNCCf9FMRZoxqobfX'],\n",
    "    'Train': ['QxGnrFQnXPGh2Lh8C'],\n",
    "    'SocialNetwork': ['dkZH6HJNQNLLDX6Aj'],\n",
    "    'TrashFOL': ['sDLK7uBCbgZon3znd'],\n",
    "    'ClassroomFOL': ['YH3ANm7Y5Qe5dSYem'],\n",
    "    'TrashRL': ['PQAJE67kz8w5NWJuM'],\n",
    "    'ClassroomRL': ['zRAn69AocpkmxXZnW'],\n",
    "    'Graphs': ['gAeD3MTGCCv8YNTaK'],\n",
    "    'LTS': ['zoEADeCW2b2suJB2k'],\n",
    "    'ProductionLine_v1': ['jyS8Bmceejj9pLbTW'],\n",
    "    'CV': ['JC8Tij8o8GZb99gEJ'],\n",
    "    'TrashLTL': ['9jPK8KBWzjFmBx4Hb']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Alloy4fun System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Alloy4fun Database With Public Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from populate_database import populate_database\n",
    "populate_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup Hint System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Hint Systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIGENA GRAPH ENDPOINTS (optional, disabled)\n",
    "\"\"\"\n",
    "for (name,ids) in name_to_model_ids.items():\n",
    "    print(send_http_request(url=\"http://localhost:8080/hint/higena-setup\",  body=ids))\n",
    "\"\"\"\n",
    "# SPECASSISTANT GRAPH ENDPOINTS\n",
    "send_http_request(url=\"http://localhost:8080/hint/debug-drop-db\", method=\"GET\")\n",
    "\n",
    "for name, ids in name_to_model_ids.items():\n",
    "    print(send_http_request(url=\"http://localhost:8080/hint/specassistant-setup?prefix=\"+name, body=ids, method=\"GET\"))\n",
    "\n",
    "# NOTE: Execution times are stored by the api application within its database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we choose the same policty for every graph for convinience, but this does not have to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=\"TED\"\n",
    "\n",
    "send_http_request(url=\"http://localhost:8080/hint/compute-all-policies-for-rule?rule=\"+policy, method=\"POST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database basic requirements\n",
    "from a4f_mongo_pipelines import *\n",
    "\n",
    "mongo_uri = \"mongodb://localhost:27017/\"\n",
    "database_name = \"meteor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get GraphId Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "\n",
    "graph_collection = db[\"Graph\"]\n",
    "\n",
    "name_to_graph_ids = {} \n",
    "\n",
    "for doc in graph_collection.aggregate(get_graph_id_dict_pipeline()):\n",
    "    name_to_graph_ids[doc[\"_id\"]] = doc[\"graph_ids\"]\n",
    "\n",
    "client.close()\n",
    "\n",
    "name_to_graph_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Graph Stats Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "\n",
    "node_collection = db[\"Node\"]\n",
    "\n",
    "data = list(node_collection.aggregate(get_graph_node_statistics()))\n",
    "\n",
    "graph_stats_df = pd.DataFrame(data)\n",
    "\n",
    "client.close()\n",
    "\n",
    "graph_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Popular Node Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: Requires GraphId Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "\n",
    "node_collection = db[\"Node\"]\n",
    "\n",
    "name_to_pop_dfs = {}\n",
    "\n",
    "for (name,graph_ids) in name_to_graph_ids.items():\n",
    "    data = list(node_collection.aggregate(get_popular_nodes_pipeline(graph_ids)))[0:30] # Limits output to first 30 entries\n",
    "    df_ = pd.DataFrame(data)\n",
    "    name_to_pop_dfs[name] = df_\n",
    "\n",
    "client.close()\n",
    "\n",
    "name_to_pop_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Min Solutions Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: Requires GraphId Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "\n",
    "node_collection = db[\"Node\"]\n",
    "\n",
    "name_to_min_sol_dfs = {}\n",
    "\n",
    "for (name,graph_ids) in name_to_graph_ids.items():\n",
    "    data = list(node_collection.aggregate(get_min_solutions_pipeline(graph_ids)))\n",
    "    df_ = pd.DataFrame(data)\n",
    "    name_to_min_sol_dfs[name] = df_\n",
    "\n",
    "client.close()\n",
    "\n",
    "name_to_min_sol_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame Persistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Write As Multiple Csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_stats_df.to_csv(path_or_buf=\"graph_stats.csv\",sep=';',float_format='%g',mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, df_) in name_to_pop_dfs.items():\n",
    "    df_.to_csv(path_or_buf=name+\".popularity.csv\",sep=';',float_format='%g',mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, df_) in name_to_min_sol_dfs.items():\n",
    "    df_.to_csv(path_or_buf=name+\".solution.csv\",sep=';',float_format='%g',mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write as Sheets of a Single XLSX File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: Requires Every DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "with pd.ExcelWriter('db_study.xlsx', engine='xlsxwriter') as writer:\n",
    "    workbook = writer.book\n",
    "    text_wrap = workbook.add_format({'text_wrap': True, 'valign': 'top'})\n",
    "    bold = workbook.add_format({'bold': True})\n",
    "    for name in sorted(list(name_to_model_ids.keys())):\n",
    "        sheet = workbook.add_worksheet(name=name)\n",
    "\n",
    "        sheet.set_column(0,0,15)\n",
    "        sheet.set_column(1,1,100,text_wrap)\n",
    "        sheet.set_column(2,2,15)\n",
    "        sheet.set_column(3,3,100,text_wrap)\n",
    "        sheet.set_column(4,4,27)\n",
    "        \n",
    "        row = 0\n",
    "        sheet.merge_range(row,0,row,len(name_to_pop_dfs[name]),\"The 30 most frequent formulas\",bold)\n",
    "        row+=1\n",
    "        name_to_pop_dfs[name].to_excel(excel_writer=writer,sheet_name=name,startrow=row, index=False)\n",
    "        row+= name_to_pop_dfs[name].shape[0] + 2\n",
    "        sheet.merge_range(row,0,row,len(name_to_min_sol_dfs[name]),\"The valid formulas ordered by their frequency\",bold)\n",
    "        row+=1\n",
    "        name_to_min_sol_dfs[name].to_excel(excel_writer=writer,sheet_name=name,startrow=row, index=False)\n",
    "        row+= name_to_min_sol_dfs[name].shape[0] + 2\n",
    "    \n",
    "    graph_stats_df.to_excel(excel_writer=writer,sheet_name=\"General Statistics\", index=False)\n",
    "    workbook.get_worksheet_by_name('General Statistics').set_column(0,0,30)\n",
    "    workbook.get_worksheet_by_name('General Statistics').set_column(1,4,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the targeted formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise = \"dkZH6HJNQNLLDX6Aj\" # Social Network\n",
    "data = pd.read_csv('formulas.csv', delimiter=';')\n",
    "\n",
    "input_data = None\n",
    "input_data = pd.read_csv('formulas.csv', delimiter=';').sort_values(by='Predicate')\n",
    "input_data = input_data.reset_index()\n",
    "\n",
    "body = dict()\n",
    "\n",
    "for index, row in input_data.iterrows():\n",
    "    try:\n",
    "        body[row['Predicate']].append(row['Formula'])\n",
    "    except KeyError:\n",
    "        body[row['Predicate']] = [row['Formula']]\n",
    "\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the result of testing each formula for each policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=requests.request(\"POST\", \"http://localhost:8080/study/test-all-policies-on-formulas?model_id=\"+exercise, json=body).json()\n",
    "df = pd.DataFrame(output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group duplicate hints, each policy hit is aggregated in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_output = dict()\n",
    "for obj in output:\n",
    "    try:\n",
    "        condensed_output[(obj['predicate'],obj['formula'],obj.get('nextFormula', None))][obj['policy']] = True\n",
    "    except KeyError:\n",
    "        copy = dict(obj)\n",
    "        policy = obj['policy']\n",
    "        copy.pop('policy',None)\n",
    "        copy[policy] = True\n",
    "        condensed_output[(obj['predicate'],obj['formula'],obj['nextFormula'])] = copy\n",
    "    \n",
    "df = pd.DataFrame(condensed_output.values())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='predicate', ascending=True)\n",
    "df.to_csv(\"hints.csv\", index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_http_request(url=\"http://localhost:8080/study/test-spec-assist\", body=name_to_graph_ids, method=\"POST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tar\n",
    "If you wish to test tar uncomment and run the following code. This process however can take days to complete as TAR is slow to process a significant amount of the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: THIS WILL TAKE A HOURS OR PERHAPS DAYS TO COMPLETE\n",
    "\n",
    "# send_http_request(url=\"http://localhost:8080/study/test-TAR\", method=\"POST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAR is not data-driven so it's accuracy does not depend on the training dataset. As a result, in our evaluations we tested TAR for every model and then limited the result view for the test sets we used. These results can be found in the file TAR_test_data.json. If you wish to use theese results you can run the following block to import them, however be advided that the specified execution times are tied to the machine specified in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import json\n",
    "\n",
    "client = pymongo.MongoClient()\n",
    "collection = client[\"meteor\"][\"Test\"]\n",
    "\n",
    "with open(\"TAR_test_data.json\", mode=\"r\") as file:\n",
    "    collection.insert_many([json.loads(line.strip())  for line in file.readlines()])\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather and Aggregate Test Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_test_data import *\n",
    "client = pymongo.MongoClient()\n",
    "collection = client[\"meteor\"][\"Test\"]\n",
    "\n",
    "data = list(collection.aggregate(extract_test_data_pipeline()))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "client.close()\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
